{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Restaurant-Sentiment-Analysis-NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMg3yvFz8L/RLvzJ5YdM+ZI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishnavipatil29/LetsUpgrade-AI-ML-/blob/master/Restaurant_Sentiment_Analysis_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9GueamPF4E0"
      },
      "source": [
        "The Aim of the project is to analyse the reviews given by customers and classify it as a positive or a negative review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ysjJaSt4EkLT",
        "outputId": "740af1b5-17b9-461f-f585-d44902b1ba2e"
      },
      "source": [
        "#Dataset\n",
        "import pandas as pd\n",
        "url='https://raw.githubusercontent.com/vaishnavipatil29/LetsUpgrade-AI-ML-/master/Restaurant_Reviews.tsv'\n",
        "df = pd.read_csv(url, delimiter=\"\\t\", quoting=3)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWcu3hxBH2ln"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZGwUO-QH0zE",
        "outputId": "a6b89609-c2ac-485c-fab8-12dc6178a63b"
      },
      "source": [
        "#Check if the dataset is balanced\n",
        "df.groupby('Liked').size()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Liked\n",
              "0    500\n",
              "1    500\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FC-Dcc2IMQW"
      },
      "source": [
        "The dataset is well-balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J1zvIXkJiO-"
      },
      "source": [
        "Analyze all on first review and then apply on the whole dataset using loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YL4iwwYIPIG",
        "outputId": "1ddd175b-0db6-42c9-ea11-2b692486d972"
      },
      "source": [
        "#remove the extra characters from the reviews: #,$,% etc.\n",
        "import re\n",
        "print(df['Review'][0])\n",
        "review = re.sub('[^a-zA-z]',' ',df['Review'][0]) #Substitute all the characters other than letters in Review by space\n",
        "print(review)\n",
        "#Convert all uppercase letters to lower case\n",
        "review=review.lower()\n",
        "print(review)\n",
        "#Remove all the stopwords such as the, an, then, if etc. \n",
        "review=review.split()\n",
        "import nltk\n",
        "nltk.download('stopwords')  #download stopwords library\n",
        "from nltk.corpus import stopwords\n",
        "review1 = [word for word in review if not word in (stopwords.words('english'))] #if word in review is not word in stopwards then the word will go in review1\n",
        "print(review1)\n",
        "#Stemming -> get the root of the word e.g: loved-->love, playing-->play\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "review1 = [ps.stem(word) for word in review1]\n",
        "print(review1)\n",
        "#Finally join all the words\n",
        "review=' '.join(review1)\n",
        "print(\"Final Review: \",review)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wow... Loved this place.\n",
            "Wow    Loved this place \n",
            "wow    loved this place \n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['wow', 'loved', 'place']\n",
            "['wow', 'love', 'place']\n",
            "Final Review:  wow love place\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHkeENcFOKgG"
      },
      "source": [
        "Problem : The data given above is in textual form(or unorganised form). But, machine learning always requires the data in an organised form:arrays, matrices, tables etc. to carry out processing. So, the next step is to form organised data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hWdgx5GOHcH",
        "outputId": "4458961b-bda5-4d05-dd2d-69ce4f20a567"
      },
      "source": [
        "#Countvectorizer is used to used to form organised data\n",
        "corpus=[]\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=3)  #Consider the 3 most occuring words from the sentence\n",
        "print(review)\n",
        "corpus.append(review) #Convert to list\n",
        "print(corpus)\n",
        "X = (cv.fit_transform(corpus)).toarray()  #text converted to matrix, 1 if the word is present and 0 if not present\n",
        "print(X)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wow love place\n",
            "['wow love place']\n",
            "[[1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uIHxCAwVYx3"
      },
      "source": [
        "Now, usual ML algorithm can be applied to X."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPI2mSdZViV9"
      },
      "source": [
        "**Apply On Whole Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShCnrSHSVhFz"
      },
      "source": [
        "#-------------------------Importing libraries-------------------------#\n",
        "import re     #regular expression for substitution\n",
        "import nltk   #natural language tool kit for stopwords\n",
        "# nltk.download('stopwords')  #download stopwords\n",
        "from nltk.stem.porter import PorterStemmer  #PorterStemmer for stemming\n",
        "\n",
        "corpus = [] #empty list for making list of all reviews\n",
        "for i in range(0,1000):\n",
        "    review = re.sub('[^a-zA-Z]',' ',df['Review'][i])  #substitue all characters other than letters by space\n",
        "    review = review.lower() #Convert all to lowercase\n",
        "    review = review.split() #split the words\n",
        "    ps = PorterStemmer()  #object to stemmer\n",
        "    review = [ ps.stem(word) for word in review if not word in set(stopwords.words('english')) ]  #delete the stopwords and do stemming \n",
        "    review = ' '.join(review) #join the words\n",
        "    corpus.append(review) #append to corpus\n",
        "  \n",
        "# Create a Bag of Words Model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=1500) #initialise object to Countvectorizer.\n",
        "X = cv.fit_transform(corpus).toarray()  #dataset feature matrix"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJN2au2gZxdQ",
        "outputId": "2993024c-f547-49a2-f105-362a2e4645d9"
      },
      "source": [
        "#Dataset\n",
        "print(X)\n",
        "y = df.iloc[:,1].values #output y\n",
        "print(y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "[1 0 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1\n",
            " 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0\n",
            " 0 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0\n",
            " 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1\n",
            " 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0\n",
            " 0 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1\n",
            " 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1\n",
            " 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1\n",
            " 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1\n",
            " 1 1 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0\n",
            " 1 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 0\n",
            " 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 0\n",
            " 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1\n",
            " 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0\n",
            " 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
            " 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1\n",
            " 1 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 1\n",
            " 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0\n",
            " 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1\n",
            " 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
            " 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M46AOHFYovYd"
      },
      "source": [
        "The dataset is ready!!\n",
        "\n",
        "Since the features are non-collinear, the classifier I have choosen Naive Bayes Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BBshFlSaJA7"
      },
      "source": [
        "#train_test spliting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlCcCznoqzaZ",
        "outputId": "99e0e224-a637-476a-fee4-231f226fbfac"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvUFFQi1q8mn"
      },
      "source": [
        "Metrics and prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9j1x5g-q4Pi",
        "outputId": "eb3f8c6e-f96f-4705-dc7f-aa2f0fef437b"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[55 42]\n",
            " [12 91]]\n",
            "0.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTpOQbSArlLC"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcfFpP0trmqh",
        "outputId": "6e8a0a68-47df-4706-803f-ce4787fe5720"
      },
      "source": [
        "Review = \"bad service\"\n",
        "input1 = [Review]\n",
        "\n",
        "input_data = cv.transform(input1).toarray()\n",
        "\n",
        "input_pred = classifier.predict(input_data)\n",
        "\n",
        "if input_pred[0]==1:\n",
        "    print(\"Review is Positive\")\n",
        "else:\n",
        "    print(\"Review is Negative\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review is Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W8H_-bLr8DS",
        "outputId": "092c4dc7-6c03-44e6-88c5-793ff15d8ba8"
      },
      "source": [
        "Review = \"nice food\"\n",
        "input1 = [Review]\n",
        "\n",
        "input_data = cv.transform(input1).toarray()\n",
        "\n",
        "input_pred = classifier.predict(input_data)\n",
        "\n",
        "if input_pred[0]==1:\n",
        "    print(\"Review is Positive\")\n",
        "else:\n",
        "    print(\"Review is Negative\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review is Positive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}